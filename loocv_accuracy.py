# uses leave-one-out random forest classifier on an inputted dataset

import pandas as pd
import statistics
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import LeaveOneOut

def find_accuracy(file_name):
    # load dataset into pandas dataframe
    df = pd.read_csv(file_name)

    # determine and print default rate (percentage of the most common occurance)
    counts = df['Group'].value_counts()
    highest_occurence = counts.max()
    default_rate = (highest_occurence / df.shape[0]) * 100
    # print(f'\nDefault Rate of Dataset: {default_rate: .2f}%')

    # split dataset into label columns and feature columns
    feats = df.drop(['Group'], axis = 1) # everything but the first column
    labels = df['Group'] # just the first column

    # Initialize leave-one-out object
    loo = LeaveOneOut()

    # Initialize random forest classifier 
    rfc_model = RandomForestClassifier(n_estimators = 128)

    # Initialize a list to store the scores
    scores_list = []

    # Iterate through training and test sets generated by leave-one-out
    for train_index, test_index in loo.split(feats):
        # Split dataset into a training and test set
        feats_train, feats_test = feats.iloc[train_index], feats.iloc[test_index]
        labels_train, labels_test = labels.iloc[train_index], labels.iloc[test_index]

        # Fit model to current training set
        rfc_model.fit(feats_train, labels_train)

        # Predict labels for test set
        y_pred = rfc_model.predict(feats_test)

        # Calculate the score for this fold
        accuracy_score = rfc_model.score(feats_test, labels_test)
        scores_list.append(accuracy_score)

    # calculate and print the average of the accuracies generated by the cv
    # print(f'{statistics.mean(scores_list)*100:.2f} ({statistics.stdev(scores_list)*100:.2f})% for {scores_list.__len__()} samples')
    return statistics.mean(scores_list)*100










